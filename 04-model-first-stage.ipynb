{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# 04-model-first-stage.R\n",
    "# Purpose: fitting spatial following model\n",
    "# Runtime: ~18 hours on NYU HPC (far more in BR)\n",
    "# Author: Pablo Barbera\n",
    "# Adaptation: Camila Lainetti de Morais\n",
    "#==============================================================================\n",
    "\n",
    "# setwd('your_location')\n",
    "source('auxiliary_functions/functions.R')\n",
    "\n",
    "matrixfile <- 'data/output/adj-matrix-tcc-filter-br.rdata'\n",
    "outputfile <- 'data/temp/stan-fit-tcc-filter-br-new.rdata'\n",
    "samplesfile <- 'data/output/samples-tcc-filter-br-new.rdata'\n",
    "resultsfile <- 'data/output/results-elites-tcc-filter-br-new.rdata'\n",
    "country <- 'TCC'\n",
    "\n",
    "# loading data\n",
    "load(matrixfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## starting values for elites (for identification purposes)\n",
    "tcc <- read.csv(\"data/output/elites-data-tcc-2.csv\", sep=\";\")\n",
    "\n",
    "parties <- merge(\n",
    "  data.frame(screen_name = colnames(y), stringsAsFactors=F),\n",
    "  tcc[,c(\"simple_screen_name\", \"simple_class\")], sort=FALSE, all.x=TRUE)$simple_class\n",
    "\n",
    "start.phi <- rep(0, length(parties))\n",
    "start.phi[parties == 'F'] <- -1\n",
    "start.phi[parties == 'A'] <- 1\n",
    "\n",
    "J <- dim(y)[1]\n",
    "\n",
    "# choosing a sample of 10,000 \"informative\" users who follow 10 or more\n",
    "# politicians, and then subsetting politicians followed by >200 of these\n",
    "\n",
    "if (J>10000){\n",
    "  J <- 10000\n",
    "  inform <- which(rowSums(y)>10)\n",
    "  set.seed(12345)\n",
    "  subset.i <- sample(inform, J)\n",
    "  y <- y[subset.i, ]\n",
    "  start.phi <- start.phi[which(colSums(y)>200)]\n",
    "  y <- y[,which(colSums(y)>200)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(y@Dimnames[[2]], file='test_stages/influencers.csv') # getting the influencers analised\n",
    "\n",
    "y_matrix <- as(y, \"matrix\")\n",
    "write.csv(y_matrix, file='test_stages/adj_matrix_smaller.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## data for model\n",
    "J <- dim(y)[1]\n",
    "K <- dim(y)[2]\n",
    "N <- J * K\n",
    "jj <- rep(1:J, times=K)\n",
    "kk <- rep(1:K, each=J)\n",
    "\n",
    "stan.data <- list(J=J, K=K, N=N, jj=jj, kk=kk, y=c(as.matrix(y)))\n",
    "\n",
    "## rest of starting values\n",
    "colK <- colSums(y) # followers sum\n",
    "rowJ <- rowSums(y) # influencers sum\n",
    "normalize <- function(x){ (x-mean(x))/sd(x) }\n",
    "\n",
    "inits <- \n",
    "  rep(\n",
    "    list(\n",
    "      list(\n",
    "        alpha=normalize(log(colK+0.0001)), # j popularity\n",
    "        sigma_alpha=1,\n",
    "        \n",
    "        beta=normalize(log(rowJ+0.0001)), # i interest\n",
    "        mu_beta=0,\n",
    "        sigma_beta=1,\n",
    "        \n",
    "        theta=rnorm(J), # i ideal point\n",
    "        \n",
    "        phi=start.phi, # j ideal point\n",
    "        mu_phi=0,\n",
    "        sigma_phi=1,\n",
    "        \n",
    "        gamma=abs(rnorm(1)) # normalization constant\n",
    "      )\n",
    "    )\n",
    "    ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages('rstan', dependencies = TRUE)\n",
    "\n",
    "# # Configure the C++ toolchain\n",
    "# dotR <- file.path(Sys.getenv(\"HOME\"), \".R\")\n",
    "# if (!file.exists(dotR)) dir.create(dotR)\n",
    "# M <- file.path(dotR, \"Makevars\")\n",
    "# if (!file.exists(M)) file.create(M)\n",
    "# cat(\"\\nCXX14FLAGS=-O3 -march=native -mtune=native\",\n",
    "#     \"CXX14 = g++\",\n",
    "#     file = M, sep = \"\\n\", append = TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: StanHeaders\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "code for methods in class “Rcpp_model_base” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_model_base” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_stan_fit” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_stan_fit” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "rstan (Version 2.21.5, GitRev: 2e1f913d3ca3)\n",
      "\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores()).\n",
      "To avoid recompilation of unchanged Stan programs, we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(rstan)\n",
    "\n",
    "stan.code <- '\n",
    "data {\n",
    "int<lower=1> J; // number of twitter users\n",
    "int<lower=1> K; // number of elite twitter accounts\n",
    "int<lower=1> N; // N = J x K\n",
    "int<lower=1,upper=J> jj[N]; // twitter user for observation n\n",
    "int<lower=1,upper=K> kk[N]; // elite account for observation n\n",
    "int<lower=0,upper=1> y[N]; // dummy if user i follows elite j\n",
    "}\n",
    "parameters {\n",
    "vector[K] alpha; // j popularity\n",
    "vector[K] phi; // j ideal point\n",
    "vector[J] beta; // i interest\n",
    "vector[J] theta; // i ideal point\n",
    "real mu_beta; // avg i interest (0)\n",
    "real<lower=0.1> sigma_beta; // std deviation i interest(1)\n",
    "real mu_phi; // avg ideal point j (0)\n",
    "real<lower=0.1> sigma_phi; // std deviation ideal point j (1)\n",
    "real<lower=0.1> sigma_alpha; // std deviation popularity j (1)\n",
    "real gamma;\n",
    "}\n",
    "model {\n",
    "alpha ~ normal(0, sigma_alpha);\n",
    "beta ~ normal(mu_beta, sigma_beta);\n",
    "phi ~ normal(mu_phi, sigma_phi);\n",
    "theta ~ normal(0, 1); \n",
    "for (n in 1:N)\n",
    "y[n] ~ bernoulli_logit( alpha[kk[n]] + beta[jj[n]] - \n",
    "gamma * square( theta[jj[n]] - phi[kk[n]] ) );\n",
    "}\n",
    "'\n",
    "rstan_options(auto_write = TRUE)\n",
    "options(mc.cores = parallel::detectCores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code for methods in class “Rcpp_stan_fit4model3c80645d1ab04_657853a628cf70c31d35851c7f35d712” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_stan_fit4model3c80645d1ab04_657853a628cf70c31d35851c7f35d712” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "Warning message:\n",
      "“There were 400 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See\n",
      "https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded”\n",
      "Warning message:\n",
      "“Examine the pairs() plot to diagnose sampling problems\n",
      "”\n",
      "Warning message:\n",
      "“The largest R-hat is 1.77, indicating chains have not mixed.\n",
      "Running the chains for more iterations may help. See\n",
      "https://mc-stan.org/misc/warnings.html#r-hat”\n",
      "Warning message:\n",
      "“Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\n",
      "Running the chains for more iterations may help. See\n",
      "https://mc-stan.org/misc/warnings.html#bulk-ess”\n",
      "Warning message:\n",
      "“Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\n",
      "Running the chains for more iterations may help. See\n",
      "https://mc-stan.org/misc/warnings.html#tail-ess”\n"
     ]
    }
   ],
   "source": [
    "# parameters for Stan model\n",
    "n.iter <- 500 # chain interactions (2000 default)\n",
    "n.warmup <- 100 # chain warmup (1000 default)\n",
    "thin <- 1\n",
    "\n",
    "## compiling model\n",
    "stan.fit <- stan(model_code=stan.code, \n",
    "                 data = stan.data,\n",
    "                 init=inits,\n",
    "                 iter=n.iter, \n",
    "                 warmup=n.warmup, \n",
    "                 chains=2, \n",
    "                 thin=1)\n",
    "\n",
    "## running model\n",
    "stan.fit <- stan(fit=stan.fit, \n",
    "                 data = stan.data, \n",
    "                 iter=n.iter, \n",
    "                 warmup=n.warmup, \n",
    "                 thin=thin, \n",
    "                 init=inits,\n",
    "                 chains=2)\n",
    "\n",
    "save(stan.fit, file=outputfile)\n",
    "\n",
    "## extracting and saving samples\n",
    "samples <- extract(stan.fit, pars=c(\"alpha\", \"phi\", \"gamma\", \"mu_beta\",\n",
    "                                    \"sigma_beta\", \"sigma_alpha\"))\n",
    "save(samples, file=samplesfile)\n",
    "\n",
    "## saving estimates\n",
    "results <- data.frame(\n",
    "   phi = apply(samples$phi, 2, mean),\n",
    "   phi.sd = apply(samples$phi, 2, sd),\n",
    "   alpha = apply(samples$alpha, 2, mean),\n",
    "   alpha.sd = apply(samples$alpha, 2, sd),\n",
    "   stringsAsFactors=F)\n",
    " \n",
    "save(results, file=resultsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
